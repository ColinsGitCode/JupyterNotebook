{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T08:33:32.305444Z",
     "start_time": "2017-12-03T08:33:32.024956Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c62e4f223138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# you can change the query for the image  here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ActiOn\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_input' is not defined"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib\n",
    "import os\n",
    "import http.cookiejar\n",
    "import json\n",
    "\n",
    "def get_soup(url,header):\n",
    "    return BeautifulSoup(urllib2.urlopen(urllib2.Request(url,headers=header)),'html.parser')\n",
    "\n",
    "\n",
    "query = raw_input(\"query image\")# you can change the query for the image  here\n",
    "image_type=\"ActiOn\"\n",
    "query= query.split()\n",
    "query='+'.join(query)\n",
    "url=\"https://www.google.co.in/search?q=\"+query+\"&source=lnms&tbm=isch\"\n",
    "print(url)\n",
    "#add the directory for your image here\n",
    "DIR=\"Pictures\"\n",
    "header={'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"\n",
    "}\n",
    "soup = get_soup(url,header)\n",
    "\n",
    "\n",
    "ActualImages=[]# contains the link for Large original images, type of  image\n",
    "for a in soup.find_all(\"div\",{\"class\":\"rg_meta\"}):\n",
    "    link , Type =json.loads(a.text)[\"ou\"]  ,json.loads(a.text)[\"ity\"]\n",
    "    ActualImages.append((link,Type))\n",
    "\n",
    "print(\"there are total\" , len(ActualImages),\"images\")\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "            os.mkdir(DIR)\n",
    "DIR = os.path.join(DIR, query.split()[0])\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "            os.mkdir(DIR)\n",
    "###print images\n",
    "for i , (img , Type) in enumerate( ActualImages):\n",
    "    try:\n",
    "        req = urllib2.Request(img, headers={'User-Agent' : header})\n",
    "        raw_img = urllib2.urlopen(req).read()\n",
    "\n",
    "        cntr = len([i for i in os.listdir(DIR) if image_type in i]) + 1\n",
    "        print(cntr)\n",
    "        if len(Type)==0:\n",
    "            f = open(os.path.join(DIR , image_type + \"_\"+ str(cntr)+\".jpg\"), 'wb')\n",
    "        else :\n",
    "            f = open(os.path.join(DIR , image_type + \"_\"+ str(cntr)+\".\"+Type), 'wb')\n",
    "\n",
    "\n",
    "        f.write(raw_img)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        print(\"could not load : \"+img)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T08:58:32.149682Z",
     "start_time": "2017-12-03T08:58:31.838319Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'urllib' has no attribute 'Request'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-11ca1f4307c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"cars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numbers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scenery\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"people\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dogs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"animals\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"animated\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msearch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-11ca1f4307c4>\u001b[0m in \u001b[0;36msearch_images\u001b[0;34m(base, terms, num_images)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mall_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-11ca1f4307c4>\u001b[0m in \u001b[0;36mget_links\u001b[0;34m(query_string, num_images)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# set user agent to avoid 403 error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Mozilla/5.0'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# returns json formatted string of the html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'Request'"
     ]
    }
   ],
   "source": [
    "'''DISCLAIMER: DUE TO COPYRIGHT ISSUES, IMAGES GATHERED SHOULD\n",
    "   ONLY BE USED FOR RESEARCH AND EDUCATION PURPOSES ONLY'''\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import urllib\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "# programtically go through google image ajax json return\n",
    "# and save links to list\n",
    "# num_images is more of a suggestion\n",
    "# it will get the ceiling of the nearest 100 if available\n",
    "\n",
    "\n",
    "def get_links(query_string, num_images):\n",
    "    # initialize place for links\n",
    "    links = []\n",
    "    # step by 100 because each return gives up to 100 links\n",
    "    for i in range(0, num_images, 10):\n",
    "        url = 'https://www.google.com/search?ei=1m7NWePfFYaGmQG51q7IBg&hl=en&q='+query_string+'\\\n",
    "        &tbm=isch&ved=0ahUKEwjjovnD7sjWAhUGQyYKHTmrC2kQuT0I7gEoAQ&start='+str(i)+'\\\n",
    "        &yv=2&vet=10ahUKEwjjovnD7sjWAhUGQyYKHTmrC2kQuT0I7gEoAQ.1m7NWePfFYaGmQG51q7IBg\\\n",
    "        .i&ijn=1&asearch=ichunk&async=_id:rg_s,_pms:s'\n",
    "\n",
    "        # set user agent to avoid 403 error\n",
    "        request = urllib.Request(url, None, {'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "        # returns json formatted string of the html\n",
    "        json_string = urllib.urlopen(request).read()\n",
    "\n",
    "        # parse as json\n",
    "        page = json.loads(json_string)\n",
    "\n",
    "        # html found here\n",
    "        html = page[1][1]\n",
    "\n",
    "        # use BeautifulSoup to parse as html\n",
    "        new_soup = Soup(html, 'lxml')\n",
    "\n",
    "        # all img tags, only returns results of search\n",
    "        imgs = new_soup.find_all('img')\n",
    "\n",
    "        # loop through images and put src in links list\n",
    "        for j in range(len(imgs)):\n",
    "            links.append(imgs[j][\"src\"])\n",
    "\n",
    "    return links\n",
    "\n",
    "# download images\n",
    "# takes list of links, directory to save to\n",
    "# and prefix for file names\n",
    "# saves images in directory as a one up number\n",
    "# with prefix added\n",
    "# all images will be .jpg\n",
    "\n",
    "\n",
    "def get_images(links, directory, pre):\n",
    "    for i in range(len(links)):\n",
    "        urllib.urlretrieve(links[i], \"./\"+directory+\"/\"+str(pre)+str(i)+\".jpg\")\n",
    "\n",
    "# main function to search images\n",
    "# takes two lists, base term and secondary terms\n",
    "# also takes number of images to download per\n",
    "# combination\n",
    "# it runs every combination of search terms\n",
    "# with base term first then secondary\n",
    "\n",
    "\n",
    "def search_images(base, terms, num_images):\n",
    "    for y in range(len(base)):\n",
    "        for x in range(len(terms)):\n",
    "            all_links = get_links(base[y]+'+'+terms[x], num_images)\n",
    "            get_images(all_links, \"images\", x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    terms = [\"cars\", \"numbers\", \"scenery\", \"people\", \"dogs\", \"cats\", \"animals\"]\n",
    "    base = [\"animated\"]\n",
    "    search_images(base, terms, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T09:26:58.826781Z",
     "start_time": "2017-12-03T09:26:58.492867Z"
    }
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-34cd6801d64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"cars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numbers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scenery\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"people\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dogs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"animals\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"animated\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msearch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-34cd6801d64e>\u001b[0m in \u001b[0;36msearch_images\u001b[0;34m(base, terms, num_images)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mall_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-34cd6801d64e>\u001b[0m in \u001b[0;36mget_links\u001b[0;34m(query_string, num_images)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# returns json formatted string of the html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# parse as json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Colin/anaconda3/envs/python27/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Colin/anaconda3/envs/python27/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Colin/anaconda3/envs/python27/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 548\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Colin/anaconda3/envs/python27/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Colin/anaconda3/envs/python27/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Colin/anaconda3/envs/python27/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "'''DISCLAIMER: DUE TO COPYRIGHT ISSUES, IMAGES GATHERED SHOULD\n",
    "   ONLY BE USED FOR RESEARCH AND EDUCATION PURPOSES ONLY'''\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import urllib2\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "# programtically go through google image ajax json return\n",
    "# and save links to list\n",
    "# num_images is more of a suggestion\n",
    "# it will get the ceiling of the nearest 100 if available\n",
    "\n",
    "\n",
    "def get_links(query_string, num_images):\n",
    "    # initialize place for links\n",
    "    links = []\n",
    "    # step by 100 because each return gives up to 100 links\n",
    "    for i in range(0, num_images, 10):\n",
    "        url = 'https://www.google.com/search?ei=1m7NWePfFYaGmQG51q7IBg&hl=en&q='+query_string+'\\\n",
    "        &tbm=isch&ved=0ahUKEwjjovnD7sjWAhUGQyYKHTmrC2kQuT0I7gEoAQ&start='+str(i)+'\\\n",
    "        &yv=2&vet=10ahUKEwjjovnD7sjWAhUGQyYKHTmrC2kQuT0I7gEoAQ.1m7NWePfFYaGmQG51q7IBg\\\n",
    "        .i&ijn=1&asearch=ichunk&async=_id:rg_s,_pms:s'\n",
    "\n",
    "        # set user agent to avoid 403 error\n",
    "        request = urllib2.Request(url, None, {'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "        # returns json formatted string of the html\n",
    "        json_string = urllib2.urlopen(request).read()\n",
    "\n",
    "        # parse as json\n",
    "        page = json.loads(json_string)\n",
    "\n",
    "        # html found here\n",
    "        html = page[1][1]\n",
    "\n",
    "        # use BeautifulSoup to parse as html\n",
    "        new_soup = Soup(html, 'lxml')\n",
    "\n",
    "        # all img tags, only returns results of search\n",
    "        imgs = new_soup.find_all('img')\n",
    "\n",
    "        # loop through images and put src in links list\n",
    "        for j in range(len(imgs)):\n",
    "            links.append(imgs[j][\"src\"])\n",
    "\n",
    "    return links\n",
    "\n",
    "# download images\n",
    "# takes list of links, directory to save to\n",
    "# and prefix for file names\n",
    "# saves images in directory as a one up number\n",
    "# with prefix added\n",
    "# all images will be .jpg\n",
    "\n",
    "\n",
    "def get_images(links, directory, pre):\n",
    "    for i in range(len(links)):\n",
    "        urllib.urlretrieve(links[i], \"./\"+directory+\"/\"+str(pre)+str(i)+\".jpg\")\n",
    "\n",
    "# main function to search images\n",
    "# takes two lists, base term and secondary terms\n",
    "# also takes number of images to download per\n",
    "# combination\n",
    "# it runs every combination of search terms\n",
    "# with base term first then secondary\n",
    "\n",
    "\n",
    "def search_images(base, terms, num_images):\n",
    "    for y in range(len(base)):\n",
    "        for x in range(len(terms)):\n",
    "            all_links = get_links(base[y]+'+'+terms[x], num_images)\n",
    "            get_images(all_links, \"images\", x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    terms = [\"cars\", \"numbers\", \"scenery\", \"people\", \"dogs\", \"cats\", \"animals\"]\n",
    "    base = [\"animated\"]\n",
    "    search_images(base, terms, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
