{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:27:02.155436Z",
     "start_time": "2017-12-27T07:27:02.144916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from unicodedata import category\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除文本中的符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:53:29.204737Z",
     "start_time": "2017-12-27T07:53:29.181326Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_strings_symbols(s):\n",
    "    NoSpecialChars = s.translate ({ord(c): \" \" for c in \"!@#$%^&*()[]{};:,./<>?\\|`~-=_+\"})\n",
    "    # s = ''.join(ch for ch in s if category(ch)[0]!= 'P')\n",
    "    return NoSpecialChars \n",
    "\n",
    "def remove_symbols_in_string(text,newsign=''):\n",
    "    signtext = string.punctuation + newsign # 引入英文符号常量，可附加自定义字符，默认为空\n",
    "    signrepl = '@'*len(signtext) # 引入符号列表长度的替换字符\n",
    "    signtable = str.maketrans(signtext,signrepl) # 生成替换字符表\n",
    "    return text.translate(signtable).replace('@','') # 最后将替换字符替换为空即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按行读取tsv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:27:04.169090Z",
     "start_time": "2017-12-27T07:27:04.152241Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_tsv_by_line(fileName):\n",
    "    '''Read .tsv files line by line and return the lines as a list''' \n",
    "    '''The return lines' element are a list which contains a string '''\n",
    "    lines = []\n",
    "    with open(fileName,'r', encoding=\"utf8\") as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\n')\n",
    "        for row in reader:\n",
    "            lines.append(row)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按行分割tab符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:27:05.319834Z",
     "start_time": "2017-12-27T07:27:05.296363Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_line_by_tab(tsvLines):\n",
    "    '''Split the class in the training datasets'''\n",
    "    '''Return the lines which ele[0] is CLASS, ele[1] is SMS_MESSAGES '''\n",
    "    newLines = []\n",
    "    EMPTY = \"\"\n",
    "    for ele in tsvLines:\n",
    "        if len(ele) == 1:\n",
    "            splitEle = ele[0].split(\"\\t\")\n",
    "            newLines.append(splitEle)\n",
    "        else:\n",
    "            splitEle = ele.split(\"\\t\")\n",
    "            newLines.append(splitEle)\n",
    "    return newLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除每一行的各种符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:28:03.772937Z",
     "start_time": "2017-12-27T07:28:03.761105Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_symbols_by_line(Lines):\n",
    "    noSymbolLines = []\n",
    "    for ele in Lines:\n",
    "        ele[1] = delete_strings_symbols(ele[1])\n",
    "        noSymbolLines.append(ele)\n",
    "    return noSymbolLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按行更新字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:27:07.809244Z",
     "start_time": "2017-12-27T07:27:07.792445Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_dictionary_by_line(line,dictionary):\n",
    "    '''Update the dictionary by line'''\n",
    "    splitedLine =line.split(\" \")\n",
    "    for w in splitedLine:\n",
    "        if w in dictionary.keys():\n",
    "            dictionary[w] += 1\n",
    "        else:\n",
    "            dictionary[w] = 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有每一行得到整个文件的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:33:33.147685Z",
     "start_time": "2017-12-27T07:33:33.137517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_whole_file_dictionary(lines):\n",
    "    dictionary = {}\n",
    "    for ele in lines:\n",
    "        dictionary = update_dictionary_by_line(ele[1],dictionary)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读文件并得到整个文件的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:56:50.388226Z",
     "start_time": "2017-12-27T07:56:50.368836Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file_and_return_each_line_and_dictionary(fileName):\n",
    "    '''Read a file and return the dictionary of the whole file'''\n",
    "    # read file and return the context by line\n",
    "    rawLines = read_tsv_by_line(fileName)\n",
    "    # delete tab in each line\n",
    "    splitedLines = split_line_by_tab(rawLines)\n",
    "    # delete symbols in each line\n",
    "    splitedLinesNoSymbol = remove_symbols_by_line(splitedLines)\n",
    "    # get the dictionary\n",
    "    dictionary = {}\n",
    "    dictionary = get_whole_file_dictionary(splitedLinesNoSymbol)\n",
    "    return splitedLinesNoSymbol, dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主程序部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:27:09.376496Z",
     "start_time": "2017-12-27T07:27:09.367656Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"sms_Copy.tsv\"\n",
    "dictionary = {}\n",
    "tsvLines = read_tsv_by_line(file)\n",
    "ClassLines = split_line_by_tab(tsvLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:27:10.198895Z",
     "start_time": "2017-12-27T07:27:10.191607Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFile = \"test_Copy.tsv\"\n",
    "testLines = read_tsv_by_line(testFile)\n",
    "NumLines = split_line_by_tab(testLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:27:10.761272Z",
     "start_time": "2017-12-27T07:27:10.751616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', \"I'm in office now da:)where are you?\"]\n",
      "['1', 'What time do u get out?']\n"
     ]
    }
   ],
   "source": [
    "print(ClassLines[0])\n",
    "print(NumLines[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:27:12.301943Z",
     "start_time": "2017-12-27T07:27:12.247990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', \"I'm in office now da:)where are you?\"]\n",
      "['ham', 'Dont pick up d call when something important is There to tell. Hrishi']\n",
      "['ham', \"Can... I'm free...\"]\n",
      "['ham', \"We'll join the  &lt;#&gt;  bus\"]\n",
      "['ham', 'You still coming tonight?']\n",
      "['ham', 'Ok...']\n",
      "['ham', \"U studying in sch or going home? Anyway i'll b going 2 sch later.\"]\n",
      "['ham', 'What does the dance river do?']\n",
      "['ham', 'Thank you. do you generally date the brothas?']\n",
      "['ham', 'Hi happy birthday. Hi hi hi hi hi hi hi']\n",
      "['ham', 'Do I? I thought I put it back in the box']\n",
      "['ham', 'Purity of friendship between two is not about smiling after reading the forwarded message..Its about smiling just by seeing the name. Gud evng']\n",
      "['ham', 'Yes ammae....life takes lot of turns you can only sit and try to hold the steering...']\n",
      "['ham', \"I'm already back home so no probably not\"]\n",
      "['ham', 'You can never do NOTHING']\n",
      "['ham', 'I love you both too :-)']\n",
      "['ham', 'Can not use foreign stamps in this country.']\n",
      "['ham', 'Shall i ask one thing if you dont mistake me.']\n",
      "['ham', 'I keep seeing weird shit and bein all \"woah\" then realising it\\'s actually reasonable and I\\'m all \"oh\"']\n",
      "['ham', 'Hey so whats the plan this sat? ']\n",
      "['ham', \"I'm meeting Darren...\"]\n",
      "['spam', 'EASTENDERS TV Quiz. What FLOWER does DOT compare herself to? D= VIOLET E= TULIP F= LILY txt D E or F to 84025 NOW 4 chance 2 WIN £100 Cash WKENT/150P16+']\n",
      "['ham', 'Babe ! How goes that day ? What are you doing ? Where are you ? I sip my cappuccino and think of you, my love ... I send a kiss to you from across the sea']\n",
      "['spam', 'Do you want a new video handset? 750 anytime any network mins? Half Price Line Rental? Camcorder? Reply or call 08000930705 for delivery tomorrow']\n",
      "['ham', 'Yes we were outside for like 2 hours. And I called my whole family to wake them up cause it started at 1 am']\n",
      "['ham', 'HARD BUT TRUE: How much you show &amp;  express your love to someone....that much it will hurt when they leave you or you get seperated...!鈥┾??〨ud evening...']\n",
      "['ham', 'Ok then i will come to ur home after half an hour']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'': 4,\n",
       " '!': 1,\n",
       " '\"oh\"': 1,\n",
       " '\"woah\"': 1,\n",
       " '&amp;': 1,\n",
       " '&lt;#&gt;': 1,\n",
       " '...': 1,\n",
       " '08000930705': 1,\n",
       " '1': 1,\n",
       " '2': 3,\n",
       " '4': 1,\n",
       " '750': 1,\n",
       " '84025': 1,\n",
       " ':-)': 1,\n",
       " '?': 3,\n",
       " 'And': 1,\n",
       " 'Anyway': 1,\n",
       " 'BUT': 1,\n",
       " 'Babe': 1,\n",
       " 'Camcorder?': 1,\n",
       " 'Can': 1,\n",
       " 'Can...': 1,\n",
       " 'Cash': 1,\n",
       " 'D': 1,\n",
       " 'D=': 1,\n",
       " 'DOT': 1,\n",
       " 'Darren...': 1,\n",
       " 'Do': 2,\n",
       " 'Dont': 1,\n",
       " 'E': 1,\n",
       " 'E=': 1,\n",
       " 'EASTENDERS': 1,\n",
       " 'F': 1,\n",
       " 'F=': 1,\n",
       " 'FLOWER': 1,\n",
       " 'Gud': 1,\n",
       " 'HARD': 1,\n",
       " 'Half': 1,\n",
       " 'Hey': 1,\n",
       " 'Hi': 2,\n",
       " 'How': 2,\n",
       " 'Hrishi': 1,\n",
       " 'I': 7,\n",
       " \"I'm\": 5,\n",
       " 'I?': 1,\n",
       " 'LILY': 1,\n",
       " 'Line': 1,\n",
       " 'NOTHING': 1,\n",
       " 'NOW': 1,\n",
       " 'Ok': 1,\n",
       " 'Ok...': 1,\n",
       " 'Price': 1,\n",
       " 'Purity': 1,\n",
       " 'Quiz.': 1,\n",
       " 'Rental?': 1,\n",
       " 'Reply': 1,\n",
       " 'Shall': 1,\n",
       " 'TRUE:': 1,\n",
       " 'TULIP': 1,\n",
       " 'TV': 1,\n",
       " 'Thank': 1,\n",
       " 'There': 1,\n",
       " 'U': 1,\n",
       " 'VIOLET': 1,\n",
       " 'WIN': 1,\n",
       " 'WKENT/150P16+': 1,\n",
       " \"We'll\": 1,\n",
       " 'What': 3,\n",
       " 'Where': 1,\n",
       " 'Yes': 2,\n",
       " 'You': 2,\n",
       " 'a': 2,\n",
       " 'about': 2,\n",
       " 'across': 1,\n",
       " 'actually': 1,\n",
       " 'after': 2,\n",
       " 'all': 2,\n",
       " 'already': 1,\n",
       " 'am': 1,\n",
       " 'ammae....life': 1,\n",
       " 'an': 1,\n",
       " 'and': 4,\n",
       " 'any': 1,\n",
       " 'anytime': 1,\n",
       " 'are': 3,\n",
       " 'ask': 1,\n",
       " 'at': 1,\n",
       " 'b': 1,\n",
       " 'back': 2,\n",
       " 'bein': 1,\n",
       " 'between': 1,\n",
       " 'birthday.': 1,\n",
       " 'both': 1,\n",
       " 'box': 1,\n",
       " 'brothas?': 1,\n",
       " 'bus': 1,\n",
       " 'by': 1,\n",
       " 'call': 2,\n",
       " 'called': 1,\n",
       " 'can': 2,\n",
       " 'cappuccino': 1,\n",
       " 'cause': 1,\n",
       " 'chance': 1,\n",
       " 'come': 1,\n",
       " 'coming': 1,\n",
       " 'compare': 1,\n",
       " 'country.': 1,\n",
       " 'd': 1,\n",
       " 'da:)where': 1,\n",
       " 'dance': 1,\n",
       " 'date': 1,\n",
       " 'day': 1,\n",
       " 'delivery': 1,\n",
       " 'do': 2,\n",
       " 'do?': 1,\n",
       " 'does': 2,\n",
       " 'doing': 1,\n",
       " 'dont': 1,\n",
       " 'evening...': 1,\n",
       " 'evng': 1,\n",
       " 'express': 1,\n",
       " 'family': 1,\n",
       " 'for': 2,\n",
       " 'foreign': 1,\n",
       " 'forwarded': 1,\n",
       " 'free...': 1,\n",
       " 'friendship': 1,\n",
       " 'from': 1,\n",
       " 'generally': 1,\n",
       " 'get': 1,\n",
       " 'goes': 1,\n",
       " 'going': 2,\n",
       " 'half': 1,\n",
       " 'handset?': 1,\n",
       " 'happy': 1,\n",
       " 'herself': 1,\n",
       " 'hi': 6,\n",
       " 'hold': 1,\n",
       " 'home': 2,\n",
       " 'home?': 1,\n",
       " 'hour': 1,\n",
       " 'hours.': 1,\n",
       " 'hurt': 1,\n",
       " 'i': 2,\n",
       " \"i'll\": 1,\n",
       " 'if': 1,\n",
       " 'important': 1,\n",
       " 'in': 4,\n",
       " 'is': 2,\n",
       " 'it': 3,\n",
       " \"it's\": 1,\n",
       " 'join': 1,\n",
       " 'just': 1,\n",
       " 'keep': 1,\n",
       " 'kiss': 1,\n",
       " 'later.': 1,\n",
       " 'leave': 1,\n",
       " 'like': 1,\n",
       " 'lot': 1,\n",
       " 'love': 3,\n",
       " 'me.': 1,\n",
       " 'meeting': 1,\n",
       " 'message..Its': 1,\n",
       " 'mins?': 1,\n",
       " 'mistake': 1,\n",
       " 'much': 2,\n",
       " 'my': 3,\n",
       " 'name.': 1,\n",
       " 'network': 1,\n",
       " 'never': 1,\n",
       " 'new': 1,\n",
       " 'no': 1,\n",
       " 'not': 3,\n",
       " 'now': 1,\n",
       " 'of': 3,\n",
       " 'office': 1,\n",
       " 'one': 1,\n",
       " 'only': 1,\n",
       " 'or': 4,\n",
       " 'outside': 1,\n",
       " 'pick': 1,\n",
       " 'plan': 1,\n",
       " 'probably': 1,\n",
       " 'put': 1,\n",
       " 'reading': 1,\n",
       " 'realising': 1,\n",
       " 'reasonable': 1,\n",
       " 'river': 1,\n",
       " 'sat?': 1,\n",
       " 'sch': 2,\n",
       " 'sea': 1,\n",
       " 'seeing': 2,\n",
       " 'send': 1,\n",
       " 'seperated...!鈥┾??〨ud': 1,\n",
       " 'shit': 1,\n",
       " 'show': 1,\n",
       " 'sip': 1,\n",
       " 'sit': 1,\n",
       " 'smiling': 2,\n",
       " 'so': 2,\n",
       " 'someone....that': 1,\n",
       " 'something': 1,\n",
       " 'stamps': 1,\n",
       " 'started': 1,\n",
       " 'steering...': 1,\n",
       " 'still': 1,\n",
       " 'studying': 1,\n",
       " 'takes': 1,\n",
       " 'tell.': 1,\n",
       " 'that': 1,\n",
       " 'the': 9,\n",
       " 'them': 1,\n",
       " 'then': 2,\n",
       " 'they': 1,\n",
       " 'thing': 1,\n",
       " 'think': 1,\n",
       " 'this': 2,\n",
       " 'thought': 1,\n",
       " 'to': 7,\n",
       " 'to?': 1,\n",
       " 'tomorrow': 1,\n",
       " 'tonight?': 1,\n",
       " 'too': 1,\n",
       " 'try': 1,\n",
       " 'turns': 1,\n",
       " 'two': 1,\n",
       " 'txt': 1,\n",
       " 'up': 2,\n",
       " 'ur': 1,\n",
       " 'use': 1,\n",
       " 'video': 1,\n",
       " 'wake': 1,\n",
       " 'want': 1,\n",
       " 'we': 1,\n",
       " 'weird': 1,\n",
       " 'were': 1,\n",
       " 'whats': 1,\n",
       " 'when': 2,\n",
       " 'whole': 1,\n",
       " 'will': 2,\n",
       " 'you': 11,\n",
       " 'you,': 1,\n",
       " 'you.': 1,\n",
       " 'you?': 1,\n",
       " 'your': 1,\n",
       " '£100': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for line in ClassLines:\n",
    "    print(line)\n",
    "    dictionary = update_dictionary_by_line(line[1],dictionary)\n",
    "dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:28:09.820416Z",
     "start_time": "2017-12-27T07:28:09.793096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 10,\n",
       " '08000930705': 1,\n",
       " '1': 1,\n",
       " '2': 3,\n",
       " '4': 1,\n",
       " '750': 1,\n",
       " '84025': 1,\n",
       " 'And': 1,\n",
       " 'Anyway': 1,\n",
       " 'BUT': 1,\n",
       " 'Babe': 1,\n",
       " 'Camcorder': 1,\n",
       " 'Can': 2,\n",
       " 'Cash': 1,\n",
       " 'D': 1,\n",
       " 'D=': 1,\n",
       " 'DOT': 1,\n",
       " 'Darren': 1,\n",
       " 'Do': 2,\n",
       " 'Dont': 1,\n",
       " 'E': 1,\n",
       " 'E=': 1,\n",
       " 'EASTENDERS': 1,\n",
       " 'F': 1,\n",
       " 'F=': 1,\n",
       " 'FLOWER': 1,\n",
       " 'Gud': 1,\n",
       " 'HARD': 1,\n",
       " 'Half': 1,\n",
       " 'Hey': 1,\n",
       " 'Hi': 2,\n",
       " 'How': 2,\n",
       " 'Hrishi': 1,\n",
       " 'I': 8,\n",
       " 'Im': 5,\n",
       " 'LILY': 1,\n",
       " 'Line': 1,\n",
       " 'NOTHING': 1,\n",
       " 'NOW': 1,\n",
       " 'Ok': 2,\n",
       " 'Price': 1,\n",
       " 'Purity': 1,\n",
       " 'Quiz': 1,\n",
       " 'Rental': 1,\n",
       " 'Reply': 1,\n",
       " 'Shall': 1,\n",
       " 'TRUE': 1,\n",
       " 'TULIP': 1,\n",
       " 'TV': 1,\n",
       " 'Thank': 1,\n",
       " 'There': 1,\n",
       " 'U': 1,\n",
       " 'VIOLET': 1,\n",
       " 'WIN': 1,\n",
       " 'WKENT150P16+': 1,\n",
       " 'Well': 1,\n",
       " 'What': 3,\n",
       " 'Where': 1,\n",
       " 'Yes': 2,\n",
       " 'You': 2,\n",
       " 'a': 2,\n",
       " 'about': 2,\n",
       " 'across': 1,\n",
       " 'actually': 1,\n",
       " 'after': 2,\n",
       " 'all': 2,\n",
       " 'already': 1,\n",
       " 'am': 1,\n",
       " 'ammaelife': 1,\n",
       " 'amp': 1,\n",
       " 'an': 1,\n",
       " 'and': 4,\n",
       " 'any': 1,\n",
       " 'anytime': 1,\n",
       " 'are': 3,\n",
       " 'ask': 1,\n",
       " 'at': 1,\n",
       " 'b': 1,\n",
       " 'back': 2,\n",
       " 'bein': 1,\n",
       " 'between': 1,\n",
       " 'birthday': 1,\n",
       " 'both': 1,\n",
       " 'box': 1,\n",
       " 'brothas': 1,\n",
       " 'bus': 1,\n",
       " 'by': 1,\n",
       " 'call': 2,\n",
       " 'called': 1,\n",
       " 'can': 2,\n",
       " 'cappuccino': 1,\n",
       " 'cause': 1,\n",
       " 'chance': 1,\n",
       " 'come': 1,\n",
       " 'coming': 1,\n",
       " 'compare': 1,\n",
       " 'country': 1,\n",
       " 'd': 1,\n",
       " 'dance': 1,\n",
       " 'date': 1,\n",
       " 'dawhere': 1,\n",
       " 'day': 1,\n",
       " 'delivery': 1,\n",
       " 'do': 3,\n",
       " 'does': 2,\n",
       " 'doing': 1,\n",
       " 'dont': 1,\n",
       " 'evening': 1,\n",
       " 'evng': 1,\n",
       " 'express': 1,\n",
       " 'family': 1,\n",
       " 'for': 2,\n",
       " 'foreign': 1,\n",
       " 'forwarded': 1,\n",
       " 'free': 1,\n",
       " 'friendship': 1,\n",
       " 'from': 1,\n",
       " 'generally': 1,\n",
       " 'get': 1,\n",
       " 'goes': 1,\n",
       " 'going': 2,\n",
       " 'half': 1,\n",
       " 'handset': 1,\n",
       " 'happy': 1,\n",
       " 'herself': 1,\n",
       " 'hi': 6,\n",
       " 'hold': 1,\n",
       " 'home': 3,\n",
       " 'hour': 1,\n",
       " 'hours': 1,\n",
       " 'hurt': 1,\n",
       " 'i': 2,\n",
       " 'if': 1,\n",
       " 'ill': 1,\n",
       " 'important': 1,\n",
       " 'in': 4,\n",
       " 'is': 2,\n",
       " 'it': 3,\n",
       " 'its': 1,\n",
       " 'join': 1,\n",
       " 'just': 1,\n",
       " 'keep': 1,\n",
       " 'kiss': 1,\n",
       " 'later': 1,\n",
       " 'leave': 1,\n",
       " 'like': 1,\n",
       " 'lot': 1,\n",
       " 'love': 3,\n",
       " 'ltgt': 1,\n",
       " 'me': 1,\n",
       " 'meeting': 1,\n",
       " 'messageIts': 1,\n",
       " 'mins': 1,\n",
       " 'mistake': 1,\n",
       " 'much': 2,\n",
       " 'my': 3,\n",
       " 'name': 1,\n",
       " 'network': 1,\n",
       " 'never': 1,\n",
       " 'new': 1,\n",
       " 'no': 1,\n",
       " 'not': 3,\n",
       " 'now': 1,\n",
       " 'of': 3,\n",
       " 'office': 1,\n",
       " 'oh': 1,\n",
       " 'one': 1,\n",
       " 'only': 1,\n",
       " 'or': 4,\n",
       " 'outside': 1,\n",
       " 'pick': 1,\n",
       " 'plan': 1,\n",
       " 'probably': 1,\n",
       " 'put': 1,\n",
       " 'reading': 1,\n",
       " 'realising': 1,\n",
       " 'reasonable': 1,\n",
       " 'river': 1,\n",
       " 'sat': 1,\n",
       " 'sch': 2,\n",
       " 'sea': 1,\n",
       " 'seeing': 2,\n",
       " 'send': 1,\n",
       " 'seperated鈥┾〨ud': 1,\n",
       " 'shit': 1,\n",
       " 'show': 1,\n",
       " 'sip': 1,\n",
       " 'sit': 1,\n",
       " 'smiling': 2,\n",
       " 'so': 2,\n",
       " 'someonethat': 1,\n",
       " 'something': 1,\n",
       " 'stamps': 1,\n",
       " 'started': 1,\n",
       " 'steering': 1,\n",
       " 'still': 1,\n",
       " 'studying': 1,\n",
       " 'takes': 1,\n",
       " 'tell': 1,\n",
       " 'that': 1,\n",
       " 'the': 9,\n",
       " 'them': 1,\n",
       " 'then': 2,\n",
       " 'they': 1,\n",
       " 'thing': 1,\n",
       " 'think': 1,\n",
       " 'this': 2,\n",
       " 'thought': 1,\n",
       " 'to': 8,\n",
       " 'tomorrow': 1,\n",
       " 'tonight': 1,\n",
       " 'too': 1,\n",
       " 'try': 1,\n",
       " 'turns': 1,\n",
       " 'two': 1,\n",
       " 'txt': 1,\n",
       " 'up': 2,\n",
       " 'ur': 1,\n",
       " 'use': 1,\n",
       " 'video': 1,\n",
       " 'wake': 1,\n",
       " 'want': 1,\n",
       " 'we': 1,\n",
       " 'weird': 1,\n",
       " 'were': 1,\n",
       " 'whats': 1,\n",
       " 'when': 2,\n",
       " 'whole': 1,\n",
       " 'will': 2,\n",
       " 'woah': 1,\n",
       " 'you': 14,\n",
       " 'your': 1,\n",
       " '£100': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICT = {}\n",
    "ClassLinesNoSymbols = remove_symbols_by_line(ClassLines)\n",
    "for line in ClassLinesNoSymbols:\n",
    "    DICT = update_dictionary_by_line(line[1],DICT)\n",
    "DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:58:40.339788Z",
     "start_time": "2017-12-27T07:58:40.124428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5074\n",
      "10754\n"
     ]
    }
   ],
   "source": [
    "eachLine,Dic = read_file_and_return_each_line_and_dictionary(\"sms_train.tsv\")\n",
    "print(len(eachLine))\n",
    "print(len(Dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T06:38:12.461179Z",
     "start_time": "2017-12-27T06:38:12.444991Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"*/@》--【】--12()测试*()\"\n",
    "\n",
    "'''去除字符串中所有的字符，可增加自定义字符'''\n",
    "def strclear(text,newsign=''):\n",
    "    import string # 引入string模块\n",
    "    signtext = string.punctuation + newsign # 引入英文符号常量，可附加自定义字符，默认为空\n",
    "    signrepl = '@'*len(signtext) # 引入符号列表长度的替换字符\n",
    "    signtable = str.maketrans(signtext,signrepl) # 生成替换字符表\n",
    "    return text.translate(signtable).replace('@','') # 最后将替换字符替换为空即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T06:36:51.993495Z",
     "start_time": "2017-12-27T06:36:51.963653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:12:12.026784Z",
     "start_time": "2017-12-27T07:12:12.018080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Im in office now dawhere are you'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strclear(ClassLines[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T07:50:35.651618Z",
     "start_time": "2017-12-27T07:50:35.642402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C  Users jeremy KLUG My Documents LiClipse Workspace \n"
     ]
    }
   ],
   "source": [
    "z = \"C:\\\\Users\\\\jeremy.KLUG\\\\My Documents\\\\LiClipse Workspace\\\\\"\n",
    "removeSpecialChars = z.translate ({ord(c): \" \" for c in \"!@#$%^&*()[]{};:,./<>?\\|`~-=_+\"})\n",
    "print(removeSpecialChars)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
