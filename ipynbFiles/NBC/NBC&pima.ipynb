{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T10:45:21.101400Z",
     "start_time": "2017-12-05T10:45:21.092779Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 处理数据\n",
    "- 处理csv数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:07:58.403223Z",
     "start_time": "2017-12-05T12:07:58.383389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadCsvFunc(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:07:58.980810Z",
     "start_time": "2017-12-05T12:07:58.955863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file {pima-indians-diabetes.data.csv} with {768} rows\n"
     ]
    }
   ],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "dataset = loadCsvFunc(filename)\n",
    "print('Loaded data file {%s} with {%d} rows' %(filename, len(dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:08:02.762399Z",
     "start_time": "2017-12-05T12:08:02.747207Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def splitDataset(dataset, splitRatio):\n",
    "\ttrainSize = int(len(dataset) * splitRatio)\n",
    "\ttrainSet = []\n",
    "\tcopy = list(dataset)\n",
    "\twhile len(trainSet) < trainSize:\n",
    "\t\tindex = random.randrange(len(copy))\n",
    "\t\ttrainSet.append(copy.pop(index))\n",
    "\treturn [trainSet, copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:08:08.706474Z",
     "start_time": "2017-12-05T12:08:08.691405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitRatio = 0.67\n",
    "train, test = splitDataset(dataset, splitRatio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:08:24.058338Z",
     "start_time": "2017-12-05T12:08:24.044237Z"
    }
   },
   "source": [
    "# 3. 提取数据特征\n",
    "- 朴素贝叶斯模型包含训练数据集中数据的特征，然后使用这个数据特征来做预测\n",
    "- 我们将数据特征的获取划分为以下的子任务：\n",
    "   - 按类别划分数据\n",
    "   - 计算均值\n",
    "   - 计算标准差\n",
    "   - 提取数据集特征\n",
    "   - 按类别提取属性特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 按类别划分数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:30:38.576363Z",
     "start_time": "2017-12-05T12:30:38.558800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "\tseparated = {}\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tif (vector[-1] not in separated):\n",
    "\t\t\tseparated[vector[-1]] = []\n",
    "\t\tseparated[vector[-1]].append(vector)\n",
    "\treturn separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:31:46.121378Z",
     "start_time": "2017-12-05T12:31:46.111350Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "separeted = separateByClass(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:31:57.703481Z",
     "start_time": "2017-12-05T12:31:57.502722Z"
    }
   },
   "source": [
    "## 3.2 计算均值\n",
    "- 我们需要计算在每个类中每个属性的均值。均值是数据的中点或者集中趋势，在计算概率时，我们用它作为高斯分布的中值。\n",
    "- 我们也需要计算每个类中每个属性的标准差。标准差描述了数据散布的偏差，在计算概率时，我们用它来刻画高斯分布中，每个属性所期望的散布。\n",
    "- 标准差是方差的平方根。方差是每个属性值与均值的离差平方的平均数。注意我们使用N-1的方法（译者注：参见无偏估计），也就是在在计算方差时，属性值的个数减1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:35:57.528171Z",
     "start_time": "2017-12-05T12:35:57.514319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def mean(numbers):\n",
    "    # 每个类中每个类的均值\n",
    "\treturn sum(numbers)/float(len(numbers))\n",
    " \n",
    "def stdev(numbers):\n",
    "    # 每个类中每个属性的标准差（N-1）方法\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "\treturn math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 按类别提取特征值\n",
    "- 合并代码，我们首先将训练数据集按照类别进行划分，然后计算每个属性的摘要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:44:27.100781Z",
     "start_time": "2017-12-05T12:44:27.079322Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "\tsummaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "\tdel summaries[-1]\n",
    "\treturn summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "\tseparated = separateByClass(dataset)\n",
    "\tsummaries = {}\n",
    "\tfor classValue, instances in separated.items():\n",
    "\t\tsummaries[classValue] = summarize(instances)\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:44:28.272492Z",
     "start_time": "2017-12-05T12:44:28.254962Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = summarizeByClass(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:44:43.632242Z",
     "start_time": "2017-12-05T12:44:43.622018Z"
    }
   },
   "source": [
    "# 4. 预测\n",
    "- 我们现在可以使用从训练数据中得到的摘要来做预测。做预测涉及到对于给定的数据样本，计算其归属于每个类的概率，然后选择具有最大概率的类作为预测结果。\n",
    "- 我们可以将这部分划分成以下任务：\n",
    "    - 计算高斯概率密度函数\n",
    "    - 计算对应类的概率\n",
    "    - 单一预测\n",
    "    - 评估精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 计算高斯概率密度函数\n",
    "- 给定来自训练数据中已知属性的均值和标准差，我们可以使用高斯函数来评估一个给定的属性值的概率。\n",
    "- 在calculateProbability()函数中，我们首先计算指数部分，然后计算等式的主干。这样可以将其很好地组织成2行。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:50:13.463648Z",
     "start_time": "2017-12-05T12:50:13.450786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def calculateProbability(x, mean, stdev):\n",
    "\texponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "\treturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 计算所属类的概率\n",
    "- 我们可以计算一个属性属于某个类的概率，那么合并一个数据样本中所有属性的概率，最后便得到整个数据样本属于某个类的概率\n",
    "- 使用乘法合并概率,在下面的calculClassProbilities()函数中，给定一个数据样本，它所属每个类别的概率，可以通过将其属性概率相乘得到。结果是一个类值到概率的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:52:21.500496Z",
     "start_time": "2017-12-05T12:52:21.480895Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "\tprobabilities = {}\n",
    "\tfor classValue, classSummaries in summaries.items():\n",
    "\t\tprobabilities[classValue] = 1\n",
    "\t\tfor i in range(len(classSummaries)):\n",
    "\t\t\tmean, stdev = classSummaries[i]\n",
    "\t\t\tx = inputVector[i]\n",
    "\t\t\tprobabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "\treturn probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 预测\n",
    "## 5.1 单一预测\n",
    "- 既然可以计算一个数据样本属于每个类的概率，那么我们可以找到最大的概率值，并返回关联的类。\n",
    "- 下面的predict()函数可以完成以上任务。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:55:05.415795Z",
     "start_time": "2017-12-05T12:55:05.396018Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "\tprobabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "\tbestLabel, bestProb = None, -1\n",
    "\tfor classValue, probability in probabilities.items():\n",
    "\t\tif bestLabel is None or probability > bestProb:\n",
    "\t\t\tbestProb = probability\n",
    "\t\t\tbestLabel = classValue\n",
    "\treturn bestLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 多重预测\n",
    "- 最后，通过对测试数据集中每个数据样本的预测，我们可以评估模型精度。getPredictions()函数可以实现这个功能，并返回每个测试样本的预测列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:57:02.884923Z",
     "start_time": "2017-12-05T12:57:02.873245Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testSet):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(testSet)):\n",
    "\t\tresult = predict(summaries, testSet[i])\n",
    "\t\tpredictions.append(result)\n",
    "\treturn predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 计算精度\n",
    "- 预测值和测试数据集中的类别值进行比较，可以计算得到一个介于0%~100%精确率作为分类的精确度。getAccuracy()函数可以计算出这个精确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T12:58:22.144352Z",
     "start_time": "2017-12-05T12:58:22.130929Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tif testSet[x][-1] == predictions[x]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T13:03:49.685853Z",
     "start_time": "2017-12-05T13:03:49.668280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\tfilename = 'pima-indians-diabetes.data.csv'\n",
    "\tsplitRatio = 0.67\n",
    "\tdataset = loadCsvFunc(filename)\n",
    "\ttrainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "\t# prepare model\n",
    "\tsummaries = summarizeByClass(trainingSet)\n",
    "\t# test model\n",
    "\tpredictions = getPredictions(summaries, testSet)\n",
    "\taccuracy = getAccuracy(testSet, predictions)\n",
    "\tprint(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T13:03:50.426046Z",
     "start_time": "2017-12-05T13:03:50.388646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.40944881889764\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
