{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T07:59:01.165195Z",
     "start_time": "2018-01-03T07:58:54.537396Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from unicodedata import category\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Datasets functions\n",
    "# ----------------------------------------------------------------------\n",
    "def delete_strings_symbols(s):\n",
    "    NoSpecialChars = s.translate ({ord(c): (\" \"+ c +\" \") for c in \"!@#$%^&*()[]{};:,./<>?\\|`~-=_+\"})\n",
    "    return NoSpecialChars \n",
    "\n",
    "def remove_symbols_in_string(text,newsign=''):\n",
    "    signtext = string.punctuation + newsign \n",
    "    signrepl = '@'*len(signtext) \n",
    "    signtable = str.maketrans(signtext,signrepl) \n",
    "    return text.translate(signtable).replace('@','') \n",
    "\n",
    "def read_tsv_by_line(fileName):\n",
    "    '''Read .tsv files line by line and return the lines as a list''' \n",
    "    '''The return lines' element are a list which contains a string '''\n",
    "    lines = []\n",
    "    with open(fileName,'r', encoding=\"utf8\") as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\n')\n",
    "        for row in reader:\n",
    "            lines.append(row)\n",
    "    return lines\n",
    "\n",
    "def split_line_by_tab(tsvLines):\n",
    "    '''Split the class in the training datasets'''\n",
    "    '''Return the lines which ele[0] is CLASS, ele[1] is SMS_MESSAGES '''\n",
    "    newLines = []\n",
    "    EMPTY = \"\"\n",
    "    for ele in tsvLines:\n",
    "        if len(ele) == 1:\n",
    "            splitEle = ele[0].split(\"\\t\")\n",
    "            newLines.append(splitEle)\n",
    "        else:\n",
    "            splitEle = ele.split(\"\\t\")\n",
    "            newLines.append(splitEle)\n",
    "    return newLines\n",
    "\n",
    "def remove_symbols_by_line(Lines):\n",
    "    noSymbolLines = []\n",
    "    for ele in Lines:\n",
    "        ele[1] = delete_strings_symbols(ele[1])\n",
    "        noSymbolLines.append(ele)\n",
    "    return noSymbolLines\n",
    "\n",
    "def update_dictionary_by_line(line,dictionary):\n",
    "    '''Update the dictionary by line'''\n",
    "    splitedLine =line.split(\" \")\n",
    "    for w in splitedLine:\n",
    "        if w in dictionary.keys():\n",
    "            dictionary[w] += 1\n",
    "        else:\n",
    "            dictionary[w] = 1\n",
    "    return dictionary\n",
    "\n",
    "def get_whole_file_dictionary(lines):\n",
    "    dictionary = {}\n",
    "    for ele in lines:\n",
    "        dictionary = update_dictionary_by_line(ele[1],dictionary)\n",
    "    return dictionary\n",
    "\n",
    "def read_file_and_return_each_line_and_dictionary(fileName):\n",
    "    '''Read a file and return the dictionary of the whole file'''\n",
    "    # read file and return the context by line\n",
    "    rawLines = read_tsv_by_line(fileName)\n",
    "    # delete tab in each line\n",
    "    splitedLines = split_line_by_tab(rawLines)\n",
    "    # delete symbols in each line\n",
    "    splitedLinesNoSymbol = remove_symbols_by_line(splitedLines)\n",
    "    # get the dictionary\n",
    "    dictionary = {}\n",
    "    dictionary = get_whole_file_dictionary(splitedLinesNoSymbol)\n",
    "    return splitedLinesNoSymbol, dictionary\n",
    "\n",
    "def each_line_to_vector(line,dictKeysList):\n",
    "    '''Return the FULL format bag-of-words vector for a line'''\n",
    "    line = line.split(\" \")\n",
    "    dictLength = len(dictKeysList)\n",
    "    vectorTemplate = [0] * dictLength\n",
    "    lineVector = vectorTemplate\n",
    "    for w in line:\n",
    "        if w in dictKeysList: \n",
    "            INDEX = dictKeysList.index(w)\n",
    "            if INDEX:\n",
    "                lineVector[INDEX] += 1\n",
    "    return lineVector\n",
    "\n",
    "def lines_to_vectors_Training(lines,dictionary):\n",
    "    linesVectors = []\n",
    "    listDictionary = list(dictionary.keys())\n",
    "    for ele in lines:\n",
    "        theVector = each_line_to_vector(ele[1],listDictionary) \n",
    "        if ele[0] == \"ham\":\n",
    "            theVector.append(0)\n",
    "        else:\n",
    "            theVector.append(1)\n",
    "        linesVectors.append(theVector)\n",
    "    return linesVectors\n",
    "\n",
    "def write_result_in_csv(predictions,csvfile):\n",
    "    with open(csvfile, \"w\") as output:\n",
    "        writer = csv.writer(output, lineterminator='\\n')\n",
    "        count = 1 \n",
    "        for val in predictions:\n",
    "            if val == 0:\n",
    "                writer.writerow([count,\"ham\"])\n",
    "                count += 1\n",
    "            else:\n",
    "                writer.writerow([count,\"spam\"])\n",
    "                count += 1\n",
    "                \n",
    "# ----------------------------------------------------------------------\n",
    "# NBC functions\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def split_dataset(dataset, splitRatio):\n",
    "    '''Split the trianing dataset by the splitRatio'''\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "\t    index = random.randrange(len(copy))\n",
    "\t    trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]\n",
    "\n",
    "def separate_by_class(dataset):\n",
    "\tseparated = {}\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tif (vector[-1] not in separated):\n",
    "\t\t\tseparated[vector[-1]] = []\n",
    "\t\tseparated[vector[-1]].append(vector)\n",
    "\treturn separated\n",
    "\n",
    "def mean(numbers):\n",
    "\treturn sum(numbers)/float(len(numbers))\n",
    " \n",
    "def stdev(numbers):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "\treturn math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "\tsummaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "\tdel summaries[-1]\n",
    "\treturn summaries\n",
    "\n",
    "def summarize_by_class(dataset):\n",
    "\tseparated = separate_by_class(dataset)\n",
    "\tsummaries = {}\n",
    "\tfor classValue, instances in separated.items():\n",
    "\t\tsummaries[classValue] = summarize(instances)\n",
    "\treturn summaries\n",
    "\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    if mean == 0 or stdev == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "        return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculateProbability_Bak(x, mean, stdev):\n",
    "\texponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "\treturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculate_class_probabilities(summaries, inputVector):\n",
    "\tprobabilities = {}\n",
    "\tfor classValue, classSummaries in summaries.items():\n",
    "\t\tprobabilities[classValue] = 1\n",
    "\t\tfor i in range(len(classSummaries)):\n",
    "\t\t\tmean, stdev = classSummaries[i]\n",
    "\t\t\tx = inputVector[i]\n",
    "\t\t\tprobabilities[classValue] *= calculate_probability(x, mean, stdev)\n",
    "\treturn probabilities\n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "\tprobabilities = calculate_class_probabilities(summaries, inputVector)\n",
    "\tbestLabel, bestProb = None, -1\n",
    "\tfor classValue, probability in probabilities.items():\n",
    "\t\tif bestLabel is None or probability > bestProb:\n",
    "\t\t\tbestProb = probability\n",
    "\t\t\tbestLabel = classValue\n",
    "\treturn bestLabel\n",
    "\n",
    "def get_predictions(summaries, testSet):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(testSet)):\n",
    "\t\tresult = predict(summaries, testSet[i])\n",
    "\t\tpredictions.append(result)\n",
    "\treturn predictions\n",
    "\n",
    "def get_accuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tif testSet[x][-1] == predictions[x]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def sms_dataset(splitRatio = 0.67):\n",
    "    trainFileLines,trainFileDict = read_file_and_return_each_line_and_dictionary(\"sms_train.tsv\")\n",
    "    trainVectors = lines_to_vectors_Training(trainFileLines,trainFileDict)\n",
    "    trainTrainingSet, trainTestSet = split_dataset(trainVectors,splitRatio) \n",
    "    summaries = summarize_by_class(trainTrainingSet)\n",
    "    trainPredictions = get_predictions(summaries, trainTestSet)\n",
    "    trainAccuracy = get_accuracy(trainTestSet, trainPredictions)\n",
    "    print(\"The Accuracy is: %f\" %trainAccuracy)\n",
    "    testFileLines,testFileDict = read_file_and_return_each_line_and_dictionary(\"sms_test.tsv\")\n",
    "    testVector = lines_to_vectors_Training(testFileLines, trainFileDict) \n",
    "    newSummaries = summarize_by_class(trainVectors)\n",
    "    testPredictions = get_predictions(newSummaries,testVector)\n",
    "    csvFileName = \"SMS_results.csv\"\n",
    "    write_result_in_csv(testPredictions,csvFileName) \n",
    "    \n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# Vector Sparse Format\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "def each_line_to_vector_sparseFormat(line,dictKeysList):\n",
    "    '''Return the FULL format bag-of-words vector for a line'''\n",
    "    line = line.split(\" \")\n",
    "    dictLength = len(dictKeysList)\n",
    "    vectorTemplate = {} # using dictionary\n",
    "    lineVector = vectorTemplate\n",
    "    for w in line:\n",
    "        if w in dictKeysList: \n",
    "            INDEX = dictKeysList.index(w)\n",
    "            if INDEX in lineVector.keys():\n",
    "                lineVector[INDEX] += 1\n",
    "            else:\n",
    "                lineVector[INDEX] = 1\n",
    "    return lineVector\n",
    "                \n",
    "\n",
    "def lines_to_vectors_Training_sparseFormat(lines,dictionary):\n",
    "    linesVectors = []\n",
    "    listDictionary = list(dictionary.keys())\n",
    "    for ele in lines:\n",
    "        theVector = each_line_to_vector_sparseFormat(ele[1],listDictionary) \n",
    "        if ele[0] == \"ham\":\n",
    "            theVector = [theVector, 0]\n",
    "        else:\n",
    "            theVector = [theVector, 1]\n",
    "        linesVectors.append(theVector)\n",
    "    return linesVectors\n",
    "\n",
    "\n",
    "def mean_by_postions(posList,Count):\n",
    "    mean = sum(posList)/float(Count)\n",
    "    return mean\n",
    " \n",
    "\n",
    "def stdev_by_positions(posList,Count):\n",
    "    avg =mean_by_postions(posList,Count)\n",
    "    Zeros = pow(0-avg,2) * (Count-len(posList))\n",
    "    NotZeros = sum([pow(x-avg,2) for x in posList])\n",
    "    variance = (Zeros + NotZeros)/float(Count)\n",
    "    return math.sqrt(variance)\n",
    "    \n",
    "\n",
    "def summarize_sparseFormat_by_class(dataset):\n",
    "    vectorCountByClass = len(dataset)\n",
    "    summaries_by_class = {}\n",
    "    for vector in dataset:\n",
    "        sparseVector = vector[0]\n",
    "        keysSparseVector = sparseVector.keys()\n",
    "        for pos in keysSparseVector:\n",
    "            if pos in summaries_by_class.keys():\n",
    "                summaries_by_class[pos].append(sparseVector[pos])\n",
    "            else:\n",
    "                summaries_by_class[pos] = [sparseVector[pos]]\n",
    "    stats_by_class = {}\n",
    "    for pos in summaries_by_class.keys():\n",
    "        thePosMean = mean_by_postions(summaries_by_class[pos],vectorCountByClass)\n",
    "        thePosStdev = stdev_by_positions(summaries_by_class[pos],vectorCountByClass)\n",
    "        stats_by_class[pos] = (thePosMean,thePosStdev)\n",
    "    return stats_by_class\n",
    "\n",
    "def summarize_by_class_sparseFormat(dataset):\n",
    "\tseparated = separate_by_class(dataset)\n",
    "\tsummaries = {}\n",
    "\tfor classValue, instances in separated.items():\n",
    "\t\tsummaries[classValue] = summarize_sparseFormat_by_class(instances)\n",
    "\treturn summaries\n",
    "\n",
    "def calculate_probability_sparseFormat(x, Mean, Stdev):\n",
    "    if Mean == 0 or Stdev == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        exponent = math.exp(-(math.pow(x-Mean,2)/(2*math.pow(Stdev,2))))\n",
    "        return (1 / (math.sqrt(2*math.pi) * Stdev)) * exponent\n",
    "    \n",
    "def calculate_class_probabilities_sparseFormat(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in classSummaries.keys():\n",
    "            mean, stdev = classSummaries[i]\n",
    "            if i in inputVector[0].keys():\n",
    "                x = inputVector[0][i]\n",
    "                probabilities[classValue] *= calculate_probability_sparseFormat(x, mean, stdev)\n",
    "            else:\n",
    "                x = 0\n",
    "                probabilities[classValue] *= calculate_probability_sparseFormat(x, mean, stdev)\n",
    "                \n",
    "    return probabilities\n",
    "\n",
    "def predict_sparseFormat(summaries, inputVector):\n",
    "\tprobabilities = calculate_class_probabilities_sparseFormat(summaries, inputVector)\n",
    "\tbestLabel, bestProb = None, -1\n",
    "\tfor classValue, probability in probabilities.items():\n",
    "\t\tif bestLabel is None or probability > bestProb:\n",
    "\t\t\tbestProb = probability\n",
    "\t\t\tbestLabel = classValue\n",
    "\treturn bestLabel\n",
    "\n",
    "def get_predictions_sparseFormat(summaries, testSet):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(testSet)):\n",
    "\t\tresult = predict_sparseFormat(summaries, testSet[i])\n",
    "\t\tpredictions.append(result)\n",
    "\treturn predictions\n",
    "\n",
    "def sms_dataset_sparseFormat(splitRatio = 0.67):\n",
    "    trainLine, trainDict = read_file_and_return_each_line_and_dictionary(\"sms_train.tsv\")\n",
    "    linesVectors = lines_to_vectors_Training_sparseFormat(trainLine,trainDict)\n",
    "    trainVectors, testVectors = split_dataset(linesVectors,splitRatio)\n",
    "    summaries= summarize_by_class_sparseFormat(trainVectors)\n",
    "    trainPredictions = get_predictions_sparseFormat(summaries, testVectors)\n",
    "    trainAccuracy = get_accuracy(testVectors, trainPredictions)\n",
    "    print(\"The Accuracy is: %f\" %trainAccuracy)\n",
    "    testFileLines,testFileDict = read_file_and_return_each_line_and_dictionary(\"sms_test.tsv\")\n",
    "    testVectors = lines_to_vectors_Training_sparseFormat(testFileLines, trainDict) \n",
    "    newSummaries = summarize_by_class_sparseFormat(linesVectors)\n",
    "    testPredictions = get_predictions_sparseFormat(newSummaries,testVectors)\n",
    "    csvFileName = \"SMS_results_sparseFormat.csv\"\n",
    "    write_result_in_csv(testPredictions,csvFileName) \n",
    "\n",
    "\n",
    "def read_net_file_return_lines_and_dictionary(fileName):\n",
    "    returnLine = []\n",
    "    dictionary = {}\n",
    "    fileLines = read_tsv_by_line(fileName)\n",
    "    for line in fileLines:\n",
    "        finalLine = []\n",
    "        commaSplitedLine = line[0].split(\",\")\n",
    "        if commaSplitedLine[0] == \"ham\":\n",
    "            classFlag = \"ham\"\n",
    "        else:\n",
    "            classFlag = \"spam\"\n",
    "        del commaSplitedLine[0]\n",
    "        ipSplited = commaSplitedLine[0].split(\".\")\n",
    "        mailSplited = commaSplitedLine[1].split(\"@\")\n",
    "        domainSplited = mailSplited[1].split(\".\")\n",
    "        if \"@\" in commaSplitedLine[2]:\n",
    "            mailSplited_one = commaSplitedLine[2].split(\"@\")\n",
    "            mailSplited_one[1] = mailSplited_one[1].split(\">\")\n",
    "            domainSplited_one = mailSplited_one[1][0].split(\".\")\n",
    "        else:\n",
    "            domainSplited_one = commaSplitedLine[2]\n",
    "        theStr = \"\"\n",
    "        for ele in ipSplited:\n",
    "            if ele in dictionary.keys():\n",
    "                dictionary[ele] += 1\n",
    "            else:\n",
    "                dictionary[ele] = 1\n",
    "            theStr = theStr + ele + \" \"\n",
    "        for ele in domainSplited:\n",
    "            if ele in dictionary.keys():\n",
    "                dictionary[ele] += 1\n",
    "            else:\n",
    "                dictionary[ele] = 1\n",
    "            theStr = theStr + ele + \" \"\n",
    "        for ele in domainSplited_one:\n",
    "            if ele in dictionary.keys():\n",
    "                dictionary[ele] += 1\n",
    "            else:\n",
    "                dictionary[ele] = 1\n",
    "            theStr = theStr + ele + \" \"\n",
    "        finalLine = [classFlag, theStr]\n",
    "        returnLine.append(finalLine)\n",
    "    return returnLine, dictionary\n",
    "\n",
    "def net_dataset_sparseFormat(splitRatio = 0.67):\n",
    "    trainLine, trainDict = read_net_file_return_lines_and_dictionary(\"net_train.csv\")\n",
    "    linesVectors = lines_to_vectors_Training_sparseFormat(trainLine,trainDict)\n",
    "    trainVectors, testVectors = split_dataset(linesVectors,splitRatio)\n",
    "    summaries= summarize_by_class_sparseFormat(trainVectors)\n",
    "    trainPredictions = get_predictions_sparseFormat(summaries, testVectors)\n",
    "    trainAccuracy = get_accuracy(testVectors, trainPredictions)\n",
    "    print(\"The Accuracy is: %f\" %trainAccuracy)\n",
    "    testFileLines,testFileDict = read_net_file_return_lines_and_dictionary(\"net_test.csv\")\n",
    "    testVectors = lines_to_vectors_Training_sparseFormat(testFileLines, trainDict) \n",
    "    newSummaries = summarize_by_class_sparseFormat(linesVectors)\n",
    "    testPredictions = get_predictions_sparseFormat(newSummaries,testVectors)\n",
    "    #csvFileName = \"NET_results_sparseFormat.csv\"\n",
    "    csvFileName = \"XUE_net.csv\"\n",
    "    write_result_in_csv(testPredictions,csvFileName) \n",
    "\n",
    "\n",
    "def net_dataset(splitRatio = 0.67):\n",
    "    trainLine, trainDict = read_net_file_return_lines_and_dictionary(\"net_train.csv\")\n",
    "    linesVectors = lines_to_vectors_Training(trainLine,trainDict)\n",
    "    trainVectors, testVectors = split_dataset(linesVectors,splitRatio)\n",
    "    summaries= summarize_by_class(trainVectors)\n",
    "    trainPredictions = get_predictions(summaries, testVectors)\n",
    "    trainAccuracy = get_accuracy(testVectors, trainPredictions)\n",
    "    print(\"The Accuracy is: %f\" %trainAccuracy)\n",
    "    testFileLines,testFileDict = read_net_file_return_lines_and_dictionary(\"net_test.csv\")\n",
    "    testVectors = lines_to_vectors_Training(testFileLines, trainDict) \n",
    "    newSummaries = summarize_by_class(linesVectors)\n",
    "    testPredictions = get_predictions(newSummaries,testVectors)\n",
    "    csvFileName = \"XUE_net_notSparse.csv\"\n",
    "    write_result_in_csv(testPredictions,csvFileName) \n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
