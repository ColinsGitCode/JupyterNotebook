{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T01:22:36.296815Z",
     "start_time": "2017-11-01T01:22:20.987104Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 常用的引用和创建对象实体\n",
    "from pyspark import SparkConf,SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"My App\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1, RDD 基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark中RDD是一个不可变的分布式对象集合，每个RDD都被分为多个分区，这些分区运行在集群中的不同节点上。\n",
    "\n",
    "RDD可以包含Python,Java,Scala中任意类型的对象，甚至可以包含用户自定义的对象。\n",
    "\n",
    "两种创建方法：1，读取外部数据集    2，在驱动器程序里分发驱动器程序中的对象集合（比如list和set）\n",
    "\n",
    "创建出来的RDD支持两种类型的操作：转化操作（transformation）和行动操作（action）\n",
    "\n",
    "转化操作会由一个RDD生成一个新的RDD, 行动操作会对RDD计算出一个结果，并把结果返回到驱动器程序中，或者存储到外部存储系统（HDFS） \n",
    "\n",
    "RDD在第一次在一个行动操作中用到时，才会真正的计算，一旦Spark了解了完整的转化操作链之后，它就可以只计算求结果时真正需要的数据\n",
    "\n",
    "默认情况下，Spark的RDD会在每次对它们进行行动操作的时重新计算\n",
    "\n",
    "如果想在多个行动操作中重用同一个RDD,可以使用RDD.persist()(cache()也有同样的效果）让Spark把这个RDD缓存下来，不重用的RDD没必要保存下来浪费内存资源\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2,创建RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最简单的方式：把一个已有的集合传给SparkContext的Parallelize()方法，但是实际应用中不常见，因为需要预先把整个数据集先放在一个机器的内存中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T01:22:37.012139Z",
     "start_time": "2017-11-01T01:22:36.298707Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.parallelize([\"pandas\",\"i like pandas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更常见的方式：从外部存储器中读取数据来创建RDD,如从文本文件中读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T01:22:38.665518Z",
     "start_time": "2017-11-01T01:22:37.019214Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt = sc.textFile(\"Examples/README.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3,RDD操作 -- 转换操作(Transformation) + 行动操作(Action)\n",
    "\n",
    "## 一些常见操作\n",
    "\n",
    "### 转化操作\n",
    "\n",
    "RDD.filter(\"过滤条件\") ## 对RDD元素中内容进行过滤，返回一个全新的RDD\n",
    "\n",
    "### 行动操作 每当调用一个新的行动操作时，整个RDD都会从头开始计算，避免这种低效的行为，可以将中间结果持久化\n",
    "\n",
    "RDD.count() ## 对返回结果进行计数\n",
    "\n",
    "RDD.take() ## 收集RDD中的一些元素\n",
    "\n",
    "RDD.collect() ## 用于收集RDD中的所有函数，collect()不能用在大数据集上\n",
    "\n",
    "## 惰性求值\n",
    "\n",
    "RDD的转化操作都是**惰性求值**的，在行动操作执行之前Spark不会开始计算。RDD不是放着特定数据的数据集，而是我们通过转化操作构建的，记录着如何处理计算数据的指令列表，同理，数据的读取操作也是惰性的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4, 向Spark传递函数\n",
    "\n",
    "## Python 情况下：\n",
    "\n",
    "1，传递较短的函数：使用lambda表达式，也可以传递顶层函数或者定义的局部函数。**切记：不要传递带有对象引用等的参数，会导致程序失败**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T01:22:38.678581Z",
     "start_time": "2017-11-01T01:22:38.667088Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 传递较短的函数：\n",
    "# 使用lambda表达式\n",
    "# word = rdd.filter(lambda s: \"error\" in s)\n",
    "# 使用定义的函数\n",
    "# def containsError(s):\n",
    "#     return \"error\" in s\n",
    "# word = rdd.filter(containsError)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5，常见的转换的操作和行动操作\n",
    "\n",
    "## 基本RDD\n",
    "\n",
    "### 针对各个元素的转化操作\n",
    "\n",
    "RDD.map()函数接受一个函数，并把这个函数用于RDD中的每一个元素，并将函数的返回结果作为结果RDD中对应的元素值。\n",
    "\n",
    "RDD.filter()函数接受一个函数，并将RDD中满足该函数的元素放入新的RDD中返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T01:22:42.473909Z",
     "start_time": "2017-11-01T01:22:38.685975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# 实例：计算RDD中各值的平方\n",
    "nums_RDD = sc.parallelize([1,2,3,4])\n",
    "squared = nums_RDD.map(lambda x: x*x).collect()\n",
    "for num in squared:\n",
    "    print(\"%i\" %num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T01:22:42.699461Z",
     "start_time": "2017-11-01T01:22:42.477327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# 实例，筛选出RDD中不是1的值\n",
    "squared = nums_RDD.filter(lambda x: x!=1).collect()\n",
    "for num in squared:\n",
    "    print(\"%i\" %num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDD.flarMap() 希望对每一个输入元素生成多个输出元素，提供给flatMap()的函数被分别用在了输入RDD的每一个元素上，返回的不是一个元素，而是一个返回值序列的迭代器。输出的RDD倒不是由迭代器组成的，我们得到的是一个报个各个迭代器且可访问的所有元素的RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T01:22:42.921300Z",
     "start_time": "2017-11-01T01:22:42.713403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world\n",
      "hi\n",
      "Worriors\n",
      "for\n",
      "the\n",
      "horde,\n",
      "bool\n",
      "and\n",
      "lighting!!!\n"
     ]
    }
   ],
   "source": [
    "# 实例： 将行数据切分为单词\n",
    "lines = sc.parallelize([\"hello world\",\"hi Worriors\",\"for the horde, bool and lighting!!!\"])\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))\n",
    "contents = words.collect()\n",
    "for Str in contents:\n",
    "    print(\"%s\" %Str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T01:22:43.095490Z",
     "start_time": "2017-11-01T01:22:42.924776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hello', 'world'], ['hi', 'Worriors'], ['for', 'the', 'horde,', 'bool', 'and', 'lighting!!!']]\n",
      "['hello', 'world']\n",
      "['hi', 'Worriors']\n",
      "['for', 'the', 'horde,', 'bool', 'and', 'lighting!!!']\n"
     ]
    }
   ],
   "source": [
    "lines = sc.parallelize([\"hello world\",\"hi Worriors\",\"for the horde, bool and lighting!!!\"])\n",
    "words = lines.map(lambda line: line.split(\" \"))\n",
    "contents = words.collect()\n",
    "print(contents)\n",
    "for content in contents:\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
