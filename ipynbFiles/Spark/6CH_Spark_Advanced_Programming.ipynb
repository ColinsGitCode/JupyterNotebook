{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-11T16:47:21.405210Z",
     "start_time": "2017-11-11T16:47:09.506723Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 常用的引用和创建对象实体\n",
    "from pyspark import SparkConf,SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"My App\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1, 简介\n",
    "1. 累加器（accumulator）: 对信息进行聚合\n",
    "2. 广播变量（broadcast variable）: 高效分发较大的对象\n",
    "3. 批操作\n",
    "4. 外部程序的交互方式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- **共享变量是一种可以在Spark任务中使用的特殊类型的变量**\n",
    "- **当任务需要很长的时间的时候，在你多个数据元素之间共享一次配置就会比较有效率**\n",
    "- Spark可以使用**pipe()**方法来与其他程序通过标准输入和标准输出进行交互\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2, 类加器 Accumulator\n",
    "- 提供了将工作节点中的值聚合到驱动器程序中的简单语法，即一种**共享变量**\n",
    "- 调用方式如下：\n",
    "   1. 在Driver中调用**SparkContext.accumulator(initialValue)的方法，创建出存有初始值的累加器,返回值为org.apache.spark.Accumulator[T]的对象，T是初始类型\n",
    "      - `blankLines = sc.accumulator(0)`\n",
    "      - 创建初始值为0的累加器*blankLines*\n",
    "      - 在某些程序中调用累加器之前需要 *glibal* 全局声明所有的累加器变量\n",
    "   2. 在Spark闭包程序中执行 +=1 对累加器进行自增值\n",
    "      - `blankLines += 1`\n",
    "   3. Driver可以调用累加器的**value**属性来访问累加器的值\n",
    "- **工作节点上的任务不能访问累加器的值，累加器是一个只写的变量，此模式下累加器的实现可以更加高效，不需要对每次更新操作进行复杂的通信**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 累加器与容错性\n",
    "- Spark会自动重新执行失败或者比较慢的任务来应对有错误的或者比较慢的机器\n",
    "- 即使没有节点失败，Spark有时也需要重新运行任务来获取缓存中被移除内存的数据\n",
    "- **对于要在Actions操作中使用的累加器，Spark只会把每个任务对各累加器的修改应用一次**\n",
    "- 如果想要一个**无论在失败还是在重复计算时都可靠的累加器**,我们必须把它放在**foreach()**这样的**Action**操作中\n",
    "- 对于在**RDD Transformation**操作中使用的累加器，就不能保证有这种情况了\n",
    "- **Transformation**操作中使用的累加器可能会发生不止一次的更新，在**Transformation**操作中，累加器常常用于调试目的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 自定义累加器\n",
    "- 可以定义任何累加器的类型，和累加器的操作，如选择最大的累加器值等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3, 广播变量 broadcast vairable\n",
    "- 也是一种共享变量\n",
    "- **让程序高效地向所有工作节点发送一个较大的*[只读值]*，以供一个或多个Spark操作使用**\n",
    "- Spark会自动把**闭包中所有引用到的变量**都放发送到工作节点上，虽方便，但低效：\n",
    "   1. 默认的任务发射机制是专门为小任务进行优化的\n",
    "   2. 事实上，程序可能会在多个并行操作中使用同一个变量，但是Spark回为每个操作分别分发。\n",
    "- **广播变量**\n",
    "   1. 类型为 **spark.broadcast.Broadcast[T]** 的一个对象\n",
    "   2. 存放着类型为 T 的值\n",
    "   3. 可以在任务中通过对**Broadcast**对象调用**value**来获取该对象的值\n",
    "   4. 这个值只会被发送到各个节点一次，使用的是一种高效的类似于BitTorrent的通信机制\n",
    "- **广播变量的使用过程**\n",
    "   1. 通过一个类型 T 的对象调用**SparkContexrt.broadcast**创建出一个**Broadcast[T]**对象，任何和序列化的类型都可以实现\n",
    "      - `signPrefixes = sc.broadcast(loadCallSignTable())`\n",
    "   2. 通过**value**属性访问该对象的值\n",
    "   3. 变量只会被发送到各个节点一次，应作为只读值处理（修改这个值不会影响到别的节点）\n",
    "   4，只能在**Driver**中进行修改\n",
    "- 广播的优化\n",
    "   1. 当广播一个较大的值时，选择既快又好的序列化格式是很重要的，因为如果序列化对象的时间很长，或者传送花费的时间太久，这段时间就会成为性能瓶颈\n",
    "   2. 最好使用基本类型的数组，也可以使用**spark.serializer**属性选择另一个序列化库来优化序列化的过程\n",
    "   3. 也可以自己实现序列化过程：Python的pickle库自定义序列化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4, 基于分区进行操作\n",
    "- 基于分区的操作可以让我们避免为每一个数据元素进行重复的配置工作。\n",
    "- Spark提供基于分区的**map**和**foreach**操作，让你的部分代码只对RDD的每个分区运行一次，这样可以帮助降低这些操作的代价\n",
    "- 基于分区操作RDD时，Spark会为函数提供该分区的元素的迭代器\n",
    "- 返回值方面，也返回一个迭代器。\n",
    "- 按分区执行的操作符：\n",
    "    - <img src=\"https://raw.githubusercontent.com/ColinsGitCode/JupyterNotebook/4976c04732ac8018a51dc0ea818ac7145c86e92e/ipynbFiles/Materials/%E6%8C%89%E5%88%86%E5%8C%BA%E6%89%A7%E8%A1%8C%E7%9A%84%E6%93%8D%E4%BD%9C%E7%AC%A6.jpg\" />\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5, 与外部程序间的管道\n",
    "- RDD.pipe()方法。从外部程序的方法或者库来对RDD中的每个元素进行一些特定的处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6, 数值RDD的操作\n",
    "- Spark对包含数值数据的RDD提供了一些描述性的统计操作。\n",
    "- Spark的数值操作都是通过流式计算实现的，允许以每次一个元素的方式构建出模型\n",
    "- 这些统计数据都会在调用**stats()**时通过一次遍历数据计算出来并以**StatsCounter**对象返回\n",
    "- **StatsCounter中可用的汇总统计数据**\n",
    "   1. count()           RDD中的元素的个数\n",
    "   2. mean()            元素的平均值\n",
    "   3. sum()             综合\n",
    "   4. max()             最大值\n",
    "   5. min()             最小值\n",
    "   6. variance()        元素的方差\n",
    "   7. sampleVariance()  从采样中计算出的方差\n",
    "   8. stdev()           标准差\n",
    "   9. sampleStdev()     采样的标准差\n",
    "-  如果只想计算其中的一个，则直接调用即可 RDD.sun()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
